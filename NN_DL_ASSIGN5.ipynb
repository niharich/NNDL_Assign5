{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niharich/NNDL_Assign5/blob/main/NN_DL_ASSIGN5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIojf9jesFca"
      },
      "outputs": [],
      "source": [
        "#importing set of libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "#Package for splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "#Tokenization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from keras.utils.np_utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkNeIwOPtf4t",
        "outputId": "c4250aff-4e14-4195-b92b-0481fb46112e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Loading the dataset as a Pandas DataFrame\n",
        "dataset = pd.read_csv('/content/gdrive/My Drive/Sentiment.csv')\n",
        "\n",
        "# Selecting only the necessary columns 'text' and 'sentiment'\n",
        "mask = dataset.columns.isin(['text', 'sentiment'])\n",
        "data = dataset.loc[:, mask]\n",
        "\n"
      ],
      "metadata": {
        "id": "F_9MkNrLtMPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Keeping only necessary columns\n",
        "data['text'] = data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
      ],
      "metadata": {
        "id": "OgLqKOk-wTI7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7509d4b-fd9e-4fc0-ec73-401a0b6531f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-4d9282c66e4b>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply(lambda x: x.lower())\n",
            "<ipython-input-4-4d9282c66e4b>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing Re tweets\n",
        "for idx, row in data.iterrows():\n",
        "    row[0] = row[0].replace('rt', ' ')"
      ],
      "metadata": {
        "id": "kezr9unryjzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Maximum words is 2000 to tokenize the sentence\n",
        "max_features = 2000\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n"
      ],
      "metadata": {
        "id": "rXTEJG_RyzqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Padding the feature matrix\n",
        "X = pad_sequences(X)\n",
        "embed_dim = 128\n",
        "#Long short-term memory (LSTM) layer\n",
        "lstm_out = 196"
      ],
      "metadata": {
        "id": "TgLvgT52y30W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createmodel():\n",
        "    model = Sequential() #Sequential Neural Network\n",
        "    #input dimension - 2000 Neurons, output dimension-128 Neurons\n",
        "    model.add(Embedding(max_features, embed_dim,input_length = X.shape[1]))\n",
        "    model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "    model.add(Dense(3,activation='softmax'))\n",
        "    model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy']) #Compiling the model\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "zMTB8dQjy65b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying label Encoding on the label matrix\n",
        "labelencoder = LabelEncoder()\n",
        "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
        "y = to_categorical(integer_encoded)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
      ],
      "metadata": {
        "id": "OwETgBSZy-2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 #Batch size 32\n",
        "model = createmodel()\n",
        "model.fit(X_train, Y_train, epochs = 1, batch_size=batch_size, verbose = 2) #verbose the higher, the more messages\n",
        "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size) #evaluating the model\n",
        "print(score)\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "qSjFXx1rzDuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45877d3b-99c1-4eba-def6-a7cb0daa076c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "291/291 - 60s - loss: 0.8207 - accuracy: 0.6458 - 60s/epoch - 207ms/step\n",
            "144/144 - 3s - loss: 0.7431 - accuracy: 0.6774 - 3s/epoch - 22ms/step\n",
            "0.7430567145347595\n",
            "0.677370011806488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.metrics_names) #metrics of the model"
      ],
      "metadata": {
        "id": "Bf2EvPG9zeic",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e04d91-cafb-4aa5-a71d-fedd6a65d6eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['loss', 'accuracy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1)Save the model and use the saved model to predict on new text data (ex, “A lot of good things are\n",
        "#happening. We are respected again throughout the world, and that's a great thing.@realDonaldTrump”)"
      ],
      "metadata": {
        "id": "gVXzUS0pN-b1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving the model\n",
        "model.save('sentimentAnalysis.h5')"
      ],
      "metadata": {
        "id": "f3kajJNlzqml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the package for importing the saved model\n",
        "from keras.models import load_model\n",
        "model= load_model('sentimentAnalysis.h5') #loading the saved model"
      ],
      "metadata": {
        "id": "xpAA1CTIzt-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(integer_encoded)\n",
        "print(data['sentiment'])"
      ],
      "metadata": {
        "id": "uDetTd52zzA1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfcc299-f13f-489b-f8b8-268773450a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 2 1 ... 2 0 2]\n",
            "0         Neutral\n",
            "1        Positive\n",
            "2         Neutral\n",
            "3        Positive\n",
            "4        Positive\n",
            "           ...   \n",
            "13866    Negative\n",
            "13867    Positive\n",
            "13868    Positive\n",
            "13869    Negative\n",
            "13870    Positive\n",
            "Name: sentiment, Length: 13871, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting on the text data\n",
        "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing.@realDonaldTrump']\n",
        "sentence = tokenizer.texts_to_sequences(sentence) # Tokenizing the sentence\n",
        "sentence = pad_sequences(sentence, maxlen=28, dtype='int32', value=0) # Padding the sentence\n",
        "sentiment_probs = model.predict(sentence, batch_size=1, verbose=2)[0] # Predicting the sentence text\n",
        "sentiment = np.argmax(sentiment_probs)\n",
        "\n",
        "print(sentiment_probs)\n",
        "if sentiment == 0:\n",
        "    print(\"Neutral\")\n",
        "elif sentiment < 0:\n",
        "    print(\"Negative\")\n",
        "elif sentiment > 0:\n",
        "    print(\"Positive\")\n",
        "else:\n",
        "    print(\"Cannot be determined\")\n"
      ],
      "metadata": {
        "id": "nmt0a-S8z3vM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a88b1fc4-fd0b-4631-bab3-05051d84f5ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - 341ms/epoch - 341ms/step\n",
            "[0.4557972  0.1548897  0.38931316]\n",
            "Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Apply GridSearchCV on the source code provided in the class"
      ],
      "metadata": {
        "id": "7ibfhqNKOjIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing Keras classifier\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "#importing Grid search CV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#initiating model to test performance by applying multiple hyper parameters\n",
        "model = KerasClassifier(build_fn=createmodel,verbose=2)\n",
        "#batch_size\n",
        "batch_size= [10, 20, 40]\n",
        "# no. of epochs\n",
        "epochs = [1, 2]\n",
        "#dictionaries\n",
        "param_grid= {'batch_size':batch_size, 'epochs':epochs}\n",
        "grid  = GridSearchCV(estimator=model, param_grid=param_grid)\n",
        "grid_result= grid.fit(X_train,Y_train) #Fitting the model\n",
        "#summarizing the  results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) #best score, best hyper parameters"
      ],
      "metadata": {
        "id": "cNyJbCLR1e3A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2159b93c-e3f1-4c84-a270-92fabb786539"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-ad60a899c796>:6: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
            "  model = KerasClassifier(build_fn=createmodel,verbose=2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "744/744 - 117s - loss: 0.8214 - accuracy: 0.6465 - 117s/epoch - 158ms/step\n",
            "186/186 - 3s - loss: 0.8155 - accuracy: 0.6611 - 3s/epoch - 15ms/step\n",
            "744/744 - 129s - loss: 0.8210 - accuracy: 0.6472 - 129s/epoch - 173ms/step\n",
            "186/186 - 3s - loss: 0.7703 - accuracy: 0.6649 - 3s/epoch - 16ms/step\n",
            "744/744 - 119s - loss: 0.8229 - accuracy: 0.6469 - 119s/epoch - 160ms/step\n",
            "186/186 - 3s - loss: 0.7621 - accuracy: 0.6719 - 3s/epoch - 16ms/step\n",
            "744/744 - 117s - loss: 0.8245 - accuracy: 0.6428 - 117s/epoch - 157ms/step\n",
            "186/186 - 4s - loss: 0.7386 - accuracy: 0.6841 - 4s/epoch - 23ms/step\n",
            "744/744 - 113s - loss: 0.8244 - accuracy: 0.6471 - 113s/epoch - 152ms/step\n",
            "186/186 - 3s - loss: 0.7677 - accuracy: 0.6787 - 3s/epoch - 15ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 120s - loss: 0.8190 - accuracy: 0.6520 - 120s/epoch - 161ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 114s - loss: 0.6743 - accuracy: 0.7175 - 114s/epoch - 153ms/step\n",
            "186/186 - 5s - loss: 0.7343 - accuracy: 0.6880 - 5s/epoch - 25ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 116s - loss: 0.8254 - accuracy: 0.6472 - 116s/epoch - 155ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 114s - loss: 0.6751 - accuracy: 0.7176 - 114s/epoch - 154ms/step\n",
            "186/186 - 3s - loss: 0.7405 - accuracy: 0.6719 - 3s/epoch - 16ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 114s - loss: 0.8250 - accuracy: 0.6472 - 114s/epoch - 154ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 110s - loss: 0.6779 - accuracy: 0.7137 - 110s/epoch - 147ms/step\n",
            "186/186 - 3s - loss: 0.7434 - accuracy: 0.6961 - 3s/epoch - 15ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 121s - loss: 0.8294 - accuracy: 0.6394 - 121s/epoch - 162ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 114s - loss: 0.6807 - accuracy: 0.7103 - 114s/epoch - 154ms/step\n",
            "186/186 - 5s - loss: 0.7482 - accuracy: 0.6798 - 5s/epoch - 28ms/step\n",
            "Epoch 1/2\n",
            "744/744 - 115s - loss: 0.8168 - accuracy: 0.6434 - 115s/epoch - 154ms/step\n",
            "Epoch 2/2\n",
            "744/744 - 110s - loss: 0.6668 - accuracy: 0.7151 - 110s/epoch - 148ms/step\n",
            "186/186 - 3s - loss: 0.7862 - accuracy: 0.6668 - 3s/epoch - 15ms/step\n",
            "372/372 - 64s - loss: 0.8387 - accuracy: 0.6439 - 64s/epoch - 172ms/step\n",
            "93/93 - 3s - loss: 0.7612 - accuracy: 0.6751 - 3s/epoch - 31ms/step\n",
            "372/372 - 69s - loss: 0.8239 - accuracy: 0.6446 - 69s/epoch - 186ms/step\n",
            "93/93 - 2s - loss: 0.7580 - accuracy: 0.6633 - 2s/epoch - 24ms/step\n",
            "372/372 - 64s - loss: 0.8308 - accuracy: 0.6403 - 64s/epoch - 173ms/step\n",
            "93/93 - 3s - loss: 0.7771 - accuracy: 0.6541 - 3s/epoch - 37ms/step\n",
            "372/372 - 64s - loss: 0.8347 - accuracy: 0.6426 - 64s/epoch - 173ms/step\n",
            "93/93 - 2s - loss: 0.7542 - accuracy: 0.6765 - 2s/epoch - 26ms/step\n",
            "372/372 - 70s - loss: 0.8265 - accuracy: 0.6402 - 70s/epoch - 188ms/step\n",
            "93/93 - 2s - loss: 0.7715 - accuracy: 0.6620 - 2s/epoch - 23ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 66s - loss: 0.8295 - accuracy: 0.6451 - 66s/epoch - 177ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 62s - loss: 0.6838 - accuracy: 0.7131 - 62s/epoch - 168ms/step\n",
            "93/93 - 2s - loss: 0.7534 - accuracy: 0.6772 - 2s/epoch - 22ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 64s - loss: 0.8250 - accuracy: 0.6443 - 64s/epoch - 172ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 61s - loss: 0.6856 - accuracy: 0.7120 - 61s/epoch - 163ms/step\n",
            "93/93 - 3s - loss: 0.7571 - accuracy: 0.6724 - 3s/epoch - 27ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 75s - loss: 0.8333 - accuracy: 0.6381 - 75s/epoch - 201ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 66s - loss: 0.6876 - accuracy: 0.7045 - 66s/epoch - 178ms/step\n",
            "93/93 - 2s - loss: 0.7798 - accuracy: 0.6697 - 2s/epoch - 23ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 68s - loss: 0.8308 - accuracy: 0.6432 - 68s/epoch - 184ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 64s - loss: 0.6771 - accuracy: 0.7073 - 64s/epoch - 172ms/step\n",
            "93/93 - 3s - loss: 0.7934 - accuracy: 0.6372 - 3s/epoch - 35ms/step\n",
            "Epoch 1/2\n",
            "372/372 - 66s - loss: 0.8298 - accuracy: 0.6413 - 66s/epoch - 178ms/step\n",
            "Epoch 2/2\n",
            "372/372 - 64s - loss: 0.6719 - accuracy: 0.7159 - 64s/epoch - 172ms/step\n",
            "93/93 - 2s - loss: 0.7940 - accuracy: 0.6674 - 2s/epoch - 21ms/step\n",
            "186/186 - 46s - loss: 0.8478 - accuracy: 0.6330 - 46s/epoch - 247ms/step\n",
            "47/47 - 1s - loss: 0.7699 - accuracy: 0.6676 - 1s/epoch - 29ms/step\n",
            "186/186 - 44s - loss: 0.8470 - accuracy: 0.6391 - 44s/epoch - 237ms/step\n",
            "47/47 - 1s - loss: 0.7725 - accuracy: 0.6600 - 1s/epoch - 31ms/step\n",
            "186/186 - 42s - loss: 0.8483 - accuracy: 0.6301 - 42s/epoch - 226ms/step\n",
            "47/47 - 1s - loss: 0.7809 - accuracy: 0.6611 - 1s/epoch - 29ms/step\n",
            "186/186 - 41s - loss: 0.8408 - accuracy: 0.6358 - 41s/epoch - 221ms/step\n",
            "47/47 - 1s - loss: 0.7464 - accuracy: 0.6841 - 1s/epoch - 29ms/step\n",
            "186/186 - 43s - loss: 0.8427 - accuracy: 0.6342 - 43s/epoch - 231ms/step\n",
            "47/47 - 1s - loss: 0.7880 - accuracy: 0.6615 - 1s/epoch - 30ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 42s - loss: 0.8474 - accuracy: 0.6365 - 42s/epoch - 228ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 37s - loss: 0.6862 - accuracy: 0.7030 - 37s/epoch - 200ms/step\n",
            "47/47 - 3s - loss: 0.7194 - accuracy: 0.6864 - 3s/epoch - 53ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 39s - loss: 0.8376 - accuracy: 0.6386 - 39s/epoch - 210ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 38s - loss: 0.6894 - accuracy: 0.7063 - 38s/epoch - 206ms/step\n",
            "47/47 - 1s - loss: 0.7575 - accuracy: 0.6875 - 1s/epoch - 30ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 44s - loss: 0.8462 - accuracy: 0.6334 - 44s/epoch - 238ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 37s - loss: 0.6938 - accuracy: 0.7034 - 37s/epoch - 200ms/step\n",
            "47/47 - 1s - loss: 0.7585 - accuracy: 0.6885 - 1s/epoch - 32ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 44s - loss: 0.8527 - accuracy: 0.6339 - 44s/epoch - 236ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 37s - loss: 0.6856 - accuracy: 0.7054 - 37s/epoch - 201ms/step\n",
            "47/47 - 2s - loss: 0.7421 - accuracy: 0.6905 - 2s/epoch - 41ms/step\n",
            "Epoch 1/2\n",
            "186/186 - 40s - loss: 0.8406 - accuracy: 0.6402 - 40s/epoch - 216ms/step\n",
            "Epoch 2/2\n",
            "186/186 - 38s - loss: 0.6750 - accuracy: 0.7162 - 38s/epoch - 205ms/step\n",
            "47/47 - 2s - loss: 0.7728 - accuracy: 0.6658 - 2s/epoch - 53ms/step\n",
            "Epoch 1/2\n",
            "233/233 - 53s - loss: 0.8269 - accuracy: 0.6440 - 53s/epoch - 227ms/step\n",
            "Epoch 2/2\n",
            "233/233 - 50s - loss: 0.6728 - accuracy: 0.7119 - 50s/epoch - 217ms/step\n",
            "Best: 0.683739 using {'batch_size': 40, 'epochs': 2}\n"
          ]
        }
      ]
    }
  ]
}